{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06ee6fc",
   "metadata": {},
   "source": [
    "### Capítulo 14: Redes Neurais Recorrentes (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3650f1",
   "metadata": {},
   "source": [
    "### Resumo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb10728",
   "metadata": {},
   "source": [
    "Este capítulo introduz as **Redes Neurais Recorrentes (RNNs)**, uma classe de redes neurais que se destaca na análise de **dados sequenciais** e na **previsão de eventos futuros**. Ao contrário das redes neurais *feedforward* tradicionais, as RNNs podem trabalhar com sequências de comprimento arbitrário, tornando-as extremamente úteis para tarefas como:\n",
    "*   Análise de **séries temporais** (por exemplo, preços de ações).\n",
    "*   **Processamento de Linguagem Natural (PNL)**, incluindo tradução automática, fala para texto e análise de sentimentos.\n",
    "*   Sistemas de **condução autônoma** (previsão de trajetórias de carros).\n",
    "\n",
    "### Neurônios Recorrentes\n",
    "\n",
    "Um neurônio recorrente é semelhante a um neurônio em uma rede *feedforward*, mas com uma **conexão apontando para trás**, alimentando sua própria saída de volta para si mesmo no próximo passo de tempo. Isso permite que a rede mantenha uma **memória** dos passos de tempo anteriores.\n",
    "\n",
    "*   **Desenrolamento no Tempo**: Para entender como funciona, a rede é conceptualmente \"desenrolada\" ao longo do eixo do tempo, criando uma cópia do neurônio para cada passo de tempo. Cada cópia recebe as entradas do passo de tempo atual e a saída da cópia anterior.\n",
    "*   **Tipos de RNNs**: Dependendo das entradas e saídas, as RNNs podem ser classificadas em:\n",
    "    *   **Sequência para Sequência**: A rede recebe uma sequência de entradas e produz uma sequência de saídas (por exemplo, tradução automática palavra por palavra).\n",
    "    *   **Sequência para Vetor**: A rede recebe uma sequência de entradas e produz um vetor de saída único (por exemplo, classificação de sentimento de uma frase).\n",
    "    *   **Vetor para Sequência**: A rede recebe um vetor de entrada único e produz uma sequência de saídas (por exemplo, geração de uma legenda para uma imagem).\n",
    "    *   **Sequência para Sequência Atrasada**: Um tipo onde o *encoder* lê a sequência completa antes que o *decoder* comece a produzir a saída (comum em tradução automática para obter melhor contexto).\n",
    "\n",
    "### RNNs Básicas no TensorFlow\n",
    "\n",
    "O TensorFlow oferece funções para criar RNNs de forma eficiente:\n",
    "\n",
    "*   **Desenrolamento Estático (`tf.contrib.rnn.static_rnn()`)**: Constrói um grafo que contém uma célula para cada passo de tempo. Embora fácil de entender, pode resultar em grafos muito grandes para sequências longas, levando a erros de falta de memória (OOM) durante a retropropagação.\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.contrib.rnn import BasicRNNCell, static_rnn\n",
    "\n",
    "    # Exemplo simplificado\n",
    "    n_inputs = 3\n",
    "    n_neurons = 5\n",
    "    n_steps = 2\n",
    "    X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "    X_seqs = tf.unstack(tf.transpose(X, perm=))\n",
    "\n",
    "    basic_cell = BasicRNNCell(num_units=n_neurons)\n",
    "    output_seqs, states = static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "    outputs = tf.transpose(tf.stack(output_seqs), perm=)\n",
    "    ```\n",
    "*   **Desenrolamento Dinâmico (`tf.nn.dynamic_rnn()`)**: Utiliza uma operação `while_loop()` para rodar a célula o número apropriado de vezes. Isso resulta em um **grafo muito menor e mais legível** no TensorBoard, e permite **trocar memória da GPU para a CPU** durante a retropropagação (`swap_memory=True`) para evitar erros de OOM.\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.contrib.rnn import BasicRNNCell\n",
    "\n",
    "    # Exemplo simplificado\n",
    "    n_inputs = 3\n",
    "    n_neurons = 5\n",
    "    n_steps = 2\n",
    "    X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "    basic_cell = BasicRNNCell(num_units=n_neurons)\n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "    ```\n",
    "*   **Sequências de Entrada de Comprimento Variável**: Para lidar com sequências de diferentes tamanhos, o parâmetro `sequence_length` pode ser usado em `dynamic_rnn()` (ou `static_rnn()`) para indicar o comprimento de cada sequência na entrada. As saídas para passos de tempo além do comprimento real da sequência serão zero.\n",
    "*   **Sequências de Saída de Comprimento Variável**: Se o comprimento da sequência de saída não for conhecido antecipadamente, uma solução comum é definir um **token de fim de sequência (EOS token)**. Qualquer saída após o EOS deve ser ignorada na função de custo.\n",
    "*   **Classificação de Sequências (Exemplo MNIST)**: As RNNs podem ser usadas para classificação, onde a saída do último passo de tempo é alimentada a uma camada *fully connected* com uma função de ativação softmax para prever a classe.\n",
    "*   **Previsão de Séries Temporais**: Para prever o próximo valor em uma série temporal, as RNNs geralmente têm uma camada de projeção de saída (`OutputProjectionWrapper`) que aplica uma camada *fully connected* linear sobre cada saída do passo de tempo.\n",
    "\n",
    "### RNNs Profundas\n",
    "\n",
    "É comum **empilhar várias camadas de células** para criar **RNNs profundas**. No TensorFlow, isso é feito usando `tf.contrib.rnn.MultiRNNCell`.\n",
    "\n",
    "*   **Distribuição entre Múltiplas GPUs**: Para distribuir RNNs profundas de forma eficiente em várias GPUs (conforme discutido no Capítulo 12), cada camada pode ser fixada a uma GPU diferente usando um *wrapper* de célula personalizado (`DeviceCellWrapper`).\n",
    "*   **Aplicação de Dropout**: Para evitar *overfitting* em RNNs profundas, o **dropout** (introduzido no Capítulo 11) pode ser aplicado. Para aplicar dropout entre as camadas da RNN, é necessário usar `tf.contrib.rnn.DropoutWrapper`, configurando `input_keep_prob` ou `output_keep_prob`. É crucial lembrar que o dropout deve ser aplicado **apenas durante o treinamento**, o que pode exigir o uso de um *placeholder* `is_training` ou grafos separados para treinamento e teste.\n",
    "\n",
    "### O Problema do Treinamento em Muitos Passos de Tempo\n",
    "\n",
    "RNNs enfrentam o problema de **gradientes desvanecentes/explodindo** (discutido no Capítulo 11) quando treinadas em sequências muito longas. Isso dificulta a aprendizagem de dependências de longo prazo.\n",
    "\n",
    "### Célula LSTM (Long Short-Term Memory)\n",
    "\n",
    "A **célula LSTM** foi proposta em 1997 como uma solução para o problema dos gradientes desvanecentes. Ela consegue detectar dependências de longo prazo nos dados e converge mais rapidamente.\n",
    "*   As células LSTM gerenciam **dois vetores de estado**: um **estado de curto prazo** `h(t)` e um **estado de longo prazo** `c(t)`.\n",
    "*   Possui **três \"portões\" (gates)** que regulam o fluxo de informação:\n",
    "    *   **Portão de Esquecimento (Forget Gate)**: Decide quais informações descartar do estado de longo prazo.\n",
    "    *   **Portão de Entrada (Input Gate)**: Decide quais informações adicionar ao estado de longo prazo.\n",
    "    *   **Portão de Saída (Output Gate)**: Decide qual parte do estado de longo prazo será lida e produzida como o estado de curto prazo e a saída.\n",
    "*   **Conexões Peephole**: Uma melhoria que permite que os portões \"observem\" o estado de longo prazo. No TensorFlow, `tf.contrib.rnn.LSTMCell` com `use_peepholes=True` implementa isso.\n",
    "\n",
    "### Célula GRU (Gated Recurrent Unit)\n",
    "\n",
    "A **célula GRU** é uma versão simplificada da célula LSTM, introduzida em 2014. Ela também aborda o problema dos gradientes desvanecentes, mas tem uma arquitetura mais simples:\n",
    "*   Combina os portões de esquecimento e entrada em um **portão de atualização**.\n",
    "*   Não possui um portão de saída separado; o **vetor de estado completo é produzido em cada passo de tempo**.\n",
    "*   Geralmente, as células GRU têm um desempenho semelhante às LSTMs.\n",
    "\n",
    "### Processamento de Linguagem Natural (PNL)\n",
    "\n",
    "As RNNs são fundamentais para PNL.\n",
    "\n",
    "*   **Embeddings de Palavras (Word Embeddings)**:\n",
    "    *   Representar palavras com vetores *one-hot* é ineficiente para grandes vocabulários, pois é esparso e não captura similaridades semânticas.\n",
    "    *   A solução comum é representar cada palavra com um **vetor denso e de baixa dimensionalidade**, chamado **embedding**. Esses embeddings são aprendidos pela rede neural durante o treinamento, de modo que **palavras semanticamente similares tenham representações vetoriais próximas**.\n",
    "    *   No TensorFlow, isso é implementado com `tf.Variable` para os embeddings e `tf.nn.embedding_lookup()` para obter o embedding de um ID de palavra.\n",
    "*   **Rede Encoder-Decoder para Tradução Automática**:\n",
    "    *   Um modelo comum consiste em um **encoder** (que processa a sentença de entrada) e um **decoder** (que gera a sentença traduzida).\n",
    "    *   A sentença de entrada (por exemplo, inglês) é alimentada ao *encoder*, e as traduções (por exemplo, francês) são produzidas pelo *decoder*. As traduções francesas também são usadas como entradas para o *decoder*, deslocadas um passo de tempo para trás. Um token `<go>` é usado para a primeira palavra do decoder, e um token `<eos>` para indicar o fim da sentença de saída.\n",
    "    *   É comum **inverter a sentença de entrada** para o *encoder* (`\"Eu bebo leite\"` torna-se `\"leite bebo Eu\"`), o que ajuda o *decoder* a ter acesso às primeiras palavras de entrada que são mais relevantes para o início da saída.\n",
    "    *   No tempo de inferência (após o treinamento), o *decoder* usa sua **própria previsão da palavra anterior como entrada para o próximo passo de tempo**.\n",
    "    *   **Detalhes Avançados**: Para otimizar o desempenho em tarefas de PNL com vocabulários grandes e comprimentos de frase variáveis, são utilizadas técnicas como:\n",
    "        *   **Bucketing e Padding**: Agrupar sentenças por comprimentos semelhantes e preencher sentenças mais curtas com tokens `<pad>`.\n",
    "        *   **Softmax Amostrado (Sampled Softmax)**: Uma técnica para estimar a perda em vocabulários muito grandes sem ter que calcular a função softmax sobre todas as palavras possíveis, o que seria computacionalmente intensivo.\n",
    "        *   **Mecanismos de Atenção (Attention Mechanisms)**: Permitem que o *decoder* \"olhe\" para partes relevantes da sequência de entrada ao fazer uma previsão, melhorando significativamente a qualidade da tradução.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3aef7",
   "metadata": {},
   "source": [
    "### Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f568d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54667527",
   "metadata": {},
   "source": [
    "#### RNNs Básicas no TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d5ecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (2, 2, 5)\n",
      "tf.Tensor(\n",
      "[[[-0.8424166   0.29035938 -0.2739727  -0.49007022 -0.5831856 ]\n",
      "  [ 0.22340691 -0.20010251  0.6592095   0.6411391   0.55818844]]\n",
      "\n",
      " [[ 0.14533989  0.4443811   0.30226803 -0.41023073  0.0806545 ]\n",
      "  [-0.9640687  -0.41499105 -0.70500284  0.775322   -0.50634515]]], shape=(2, 2, 5), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "timesteps = 2\n",
    "batch_size = 2\n",
    "\n",
    "# Criando o modelo RNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(n_neurons, activation='tanh', \n",
    "                             return_sequences=True, \n",
    "                             input_shape=(timesteps, n_inputs))\n",
    "])\n",
    "\n",
    "# Dados de entrada\n",
    "X = tf.random.normal((batch_size, timesteps, n_inputs))\n",
    "\n",
    "# Forward pass\n",
    "output = model(X)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0da8f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (4, 2, 5)\n",
      "Output at t=0: [[ 0.65454847 -0.7930878  -0.79813707  0.8771043  -0.03404181]\n",
      " [ 0.5831427  -0.8046905  -0.9999951   0.9968557  -0.6669834 ]\n",
      " [ 0.5014251  -0.8157094  -1.          0.99992424 -0.91805726]\n",
      " [-0.84629315  0.99660844 -0.9999997  -0.94724274 -0.23252378]]\n",
      "Output at t=1: [[-9.6196139e-01 -2.3785049e-01 -1.0000000e+00  9.9981207e-01\n",
      "  -9.8382586e-01]\n",
      " [-6.7851985e-01 -8.9003277e-01  1.3682653e-01  6.7586333e-01\n",
      "   1.6345747e-01]\n",
      " [-9.4484872e-01 -3.8059992e-01 -1.0000000e+00  9.9765360e-01\n",
      "  -8.4935224e-01]\n",
      " [-7.0952058e-01  9.4043958e-01 -9.9921685e-01  8.5699535e-04\n",
      "   7.3482496e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Dados de entrada combinados (batch_size, timesteps, features)\n",
    "X_batch = np.array([\n",
    "    [[0,1,2], [9,8,7]],    # amostra 1: t0 e t1\n",
    "    [[3,4,5], [0,0,0]],    # amostra 2: t0 e t1  \n",
    "    [[6,7,8], [6,5,4]],    # amostra 3: t0 e t1\n",
    "    [[9,0,1], [3,2,1]]     # amostra 4: t0 e t1\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Criar modelo RNN simples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(5, activation='tanh', return_sequences=True)\n",
    "])\n",
    "\n",
    "# Forward pass\n",
    "output = model(X_batch)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output at t=0:\", output[:, 0, :].numpy())\n",
    "print(\"Output at t=1:\", output[:, 1, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0157863",
   "metadata": {},
   "source": [
    "#### Desenrolamento estocástico através do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb084fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape da sequência de saída: (2, 2, 5)\n",
      "y0: [[-0.9393268  -0.5258273  -0.8863454   0.6789909  -0.9827231 ]\n",
      " [-0.99975455  0.7592788  -0.99997675  0.71830785 -0.9999709 ]]\n",
      "y1: [[-0.9999988   0.999221   -1.         -0.22900786 -0.9999992 ]\n",
      " [ 0.21299376 -0.7309075  -0.91290987  0.6290966   0.45839295]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Dados de entrada combinados\n",
    "X_batch = np.array([\n",
    "    [[0,1,2], [9,8,7]],  # Amostra 1: [t0, t1]\n",
    "    [[3,4,5], [0,0,0]]   # Amostra 2: [t0, t1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Criar modelo RNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(n_neurons, \n",
    "                             activation='tanh',\n",
    "                             return_sequences=True,\n",
    "                             input_shape=(2, n_inputs))\n",
    "])\n",
    "\n",
    "# Obter saídas\n",
    "output_sequence = model(X_batch)\n",
    "y0 = output_sequence[:, 0, :]  # Primeiro timestep\n",
    "y1 = output_sequence[:, 1, :]  # Segundo timestep\n",
    "\n",
    "print(\"Shape da sequência de saída:\", output_sequence.shape)\n",
    "print(\"y0:\", y0.numpy())\n",
    "print(\"y1:\", y1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b9587",
   "metadata": {},
   "source": [
    "treinando um classificador de sequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3897d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\ttf.keras.layers.SimpleRNN(n_neurons, activation='tanh', input_shape=(n_steps, n_inputs)),\n",
    "\ttf.keras.layers.Dense(n_outputs)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "\tloss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m190/400\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6911 - loss: 0.9835"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Carregar e pré-processar dados\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 28, 28)\n",
    "\n",
    "# Parâmetros\n",
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "# Modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(150, activation='tanh', input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks para monitoramento\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3),\n",
    "    tf.keras.callbacks.CSVLogger('training_log.csv')\n",
    "]\n",
    "\n",
    "# Treinar com fit() (maneira mais eficiente)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Avaliação final\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nAcurácia final no teste: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e272f",
   "metadata": {},
   "source": [
    "### Treinando para prever séries temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb3363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "# Usando Keras API (TF2 style)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(n_neurons, activation='relu', \n",
    "                             return_sequences=False,\n",
    "                             input_shape=(n_steps, n_inputs)),\n",
    "    tf.keras.layers.Dense(n_outputs)\n",
    "])\n",
    "\n",
    "# Alternativa: se você quer acesso às saídas de cada timestep\n",
    "model_with_states = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(n_neurons, activation='relu',\n",
    "                             return_sequences=True,  # Retorna todos os outputs\n",
    "                             return_state=False,     # Não retorna estado final\n",
    "                             input_shape=(n_steps, n_inputs)),\n",
    "    tf.keras.layers.Dense(n_outputs)\n",
    "])\n",
    "\n",
    "# Compilar\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Exemplo de uso:\n",
    "# X_batch shape: (batch_size, 20, 1)\n",
    "# y_batch shape: (batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6769ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9922\n",
      "Epoch 2/7\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9845\n",
      "Epoch 3/7\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9835\n",
      "Epoch 4/7\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9807\n",
      "Epoch 5/7\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9777\n",
      "Epoch 6/7\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9751\n",
      "Epoch 7/7\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9729\n",
      "Treinamento batch a batch:\n",
      "0\tMSE: 0.972500\n",
      "100\tMSE: 0.986751\n",
      "200\tMSE: 1.009069\n",
      "300\tMSE: 1.008505\n",
      "400\tMSE: 1.011735\n",
      "500\tMSE: 1.005176\n",
      "600\tMSE: 1.006412\n",
      "700\tMSE: 1.006791\n",
      "800\tMSE: 1.005621\n",
      "900\tMSE: 1.006976\n",
      "1000\tMSE: 1.005481\n",
      "1100\tMSE: 1.003946\n",
      "1200\tMSE: 1.001801\n",
      "1300\tMSE: 1.001776\n",
      "1400\tMSE: 1.000297\n",
      "\n",
      "MSE final no teste: 0.963784\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Parâmetros\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "# Definir modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(n_neurons, activation='relu', \n",
    "                             input_shape=(n_steps, n_inputs)),\n",
    "    tf.keras.layers.Dense(n_outputs)\n",
    "])\n",
    "\n",
    "# Compilar\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Função para gerar batches (substitua com seus dados)\n",
    "def next_batch(batch_size, n_steps):\n",
    "    # Dados de exemplo - substitua com dataset real\n",
    "    X_batch = np.random.randn(batch_size, n_steps, n_inputs).astype(np.float32)\n",
    "    y_batch = np.random.randn(batch_size, n_outputs).astype(np.float32)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "# Dataset completo (exemplo)\n",
    "X_full = np.random.randn(10000, n_steps, n_inputs).astype(np.float32)\n",
    "y_full = np.random.randn(10000, n_outputs).astype(np.float32)\n",
    "\n",
    "# Opção A: Usando fit() com dataset (Recomendado)\n",
    "history = model.fit(\n",
    "    X_full, y_full,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_iterations // (len(X_full) // batch_size),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Opção B: Treino manual batch a batch\n",
    "print(\"Treinamento batch a batch:\")\n",
    "for iteration in range(n_iterations):\n",
    "    X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "    \n",
    "    # Treinar no batch\n",
    "    loss = model.train_on_batch(X_batch, y_batch)\n",
    "    \n",
    "    if iteration % 100 == 0:\n",
    "        print(f\"{iteration}\\tMSE: {loss:.6f}\")\n",
    "\n",
    "# Avaliar\n",
    "test_loss = model.evaluate(X_full[:1000], y_full[:1000], verbose=0)\n",
    "print(f\"\\nMSE final no teste: {test_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191aae2",
   "metadata": {},
   "source": [
    "### Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1cf54",
   "metadata": {},
   "source": [
    "1. Você pode pensar em algumas aplicações para uma RNN de sequência-a-sequência? Que tal uma RNN sequência-vetor? E uma RNN vetor-a-sequência?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bb6d7",
   "metadata": {},
   "source": [
    "RNN Sequência-a-Sequência (Sequence-to-Sequence).\n",
    "As RNNs sequência-a-sequência são amplamente utilizadas em tarefas onde tanto a entrada quanto a saída são sequências temporais. Aplicações notáveis incluem:\n",
    "\n",
    "- **Tradução Automática**: Converter sequências de palavras de um idioma para outro (ex: Inglês → Português)\n",
    "- **Sumarização de Texto**: Transformar documentos longos em resumos concisos\n",
    "- **Tradução de Voz para Texto**: Converter sequências de áudio em texto transcrito\n",
    "- **Chatbots e Sistemas de Diálogo**: Gerar respostas sequenciais baseadas em sequências de entrada\n",
    "- **Análise de Sentimento em Tempo Real**: Processar fluxos contínuos de texto para análise de sentimentos\n",
    "- **Correção Gramatical**: Identificar e corrigir erros em sequências textuais\n",
    "\n",
    "RNN Sequência-a-Vetor (Sequence-to-Vector).\n",
    "Esta arquitetura processa sequências e produz uma saída fixa (vetor). Aplicações comuns:\n",
    "\n",
    "- **Classificação de Texto**: Analisar documentos inteiros para classificação por tópico ou sentimento\n",
    "- **Análise de Séries Temporais**: Processar históricos temporais para prever categorias ou estados futuros\n",
    "- **Reconhecimento de Fala**: Converter sequências de áudio em comandos ou palavras-chave específicas\n",
    "- **Análise de Vídeo**: Processar frames sequenciais para classificação de ações ou atividades\n",
    "- **Monitoramento de Equipamentos**: Analisar sequências de sensores para detectar falhas ou anomalias\n",
    "- **Bioinformática**: Classificar sequências de DNA ou proteínas em categorias funcionais\n",
    "\n",
    "RNN Vetor-a-Sequência (Vector-to-Sequence).\n",
    "Esta arquitetura transforma uma entrada fixa (vetor) em uma sequência temporal. Aplicações interessantes:\n",
    "\n",
    "- **Geração de Texto**: Criar textos, poemas ou histórias a partir de um vetor de seed ou prompt\n",
    "- **Síntese de Voz**: Converter representações textuais ou semânticas em sequências de áudio\n",
    "- **Geração de Música**: Compor sequências musicais a partir de representações de estilo ou emoção\n",
    "- **Descrição de Imagens**: Gerar descrições textuais sequenciais a partir de representações vetoriais de imagens\n",
    "- **Planejamento de Trajetórias**: Converter estados iniciais em sequências de movimentos ou ações\n",
    "- **Sistemas de Recomendação Sequencial**: Gerar sequências de recomendações personalizadas baseadas em perfis de usuário\n",
    "\n",
    "Cada arquitetura possui vantagens específicas dependendo da natureza do problema, sendo fundamental escolher a abordagem adequada para a tarefa em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd0d90",
   "metadata": {},
   "source": [
    "3. Como você poderia combinar uma rede neural convolucional com uma RNN para classificar vídeos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e87ad",
   "metadata": {},
   "source": [
    "Para classificar vídeos, uma abordagem comum é combinar redes neurais convolucionais (CNNs) com redes neurais recorrentes (RNNs), aproveitando o melhor de cada arquitetura:\n",
    "\n",
    "- **CNNs** são excelentes para extrair características espaciais de imagens (por exemplo, identificar objetos, texturas e padrões em cada frame do vídeo).\n",
    "- **RNNs** (como LSTM ou GRU) são ideais para modelar dependências temporais, ou seja, entender como as informações mudam ao longo do tempo entre os frames.\n",
    "\n",
    "**Estratégia típica:**\n",
    "1. **Extração de características por frame:**\n",
    "   - Cada frame do vídeo é processado individualmente por uma CNN pré-treinada (como ResNet, VGG, etc.), gerando um vetor de características para cada frame.\n",
    "2. **Sequência de vetores:**\n",
    "   - Os vetores de características extraídos de todos os frames formam uma sequência temporal (um tensor de forma `[n_frames, n_features]`).\n",
    "3. **Modelagem temporal:**\n",
    "   - Essa sequência é então alimentada em uma RNN (LSTM, GRU, etc.), que aprende as relações temporais entre os frames.\n",
    "4. **Classificação:**\n",
    "   - A saída final da RNN (ou de uma camada densa subsequente) é usada para prever a classe do vídeo (por exemplo, ação, evento, categoria).\n",
    "\n",
    "**Resumo visual:**\n",
    "```\n",
    "Frame 1   Frame 2   ...   Frame N\n",
    "   |         |              |\n",
    " CNN       CNN            CNN\n",
    "   |         |              |\n",
    "Feature1  Feature2  ...  FeatureN\n",
    "   |__________________________|\n",
    "             |\n",
    "           RNN\n",
    "             |\n",
    "        Classificação\n",
    "```\n",
    "\n",
    "**Vantagens:**\n",
    "- Permite capturar tanto informações espaciais (o que está em cada frame) quanto temporais (como as coisas mudam ao longo do vídeo).\n",
    "- Pode ser expandido para tarefas como detecção de ações, legendagem de vídeos, etc.\n",
    "\n",
    "**Exemplo de uso em TensorFlow/Keras:**\n",
    "- `TimeDistributed(CNN)` para aplicar a CNN em cada frame.\n",
    "- `LSTM` ou `GRU` para processar a sequência de vetores de características.\n",
    "\n",
    "Essa combinação é padrão em muitos sistemas de reconhecimento de vídeo modernos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dc89a",
   "metadata": {},
   "source": [
    "4. Quais são as vantagens de construir uma RNN utilizando dynamic_rnn() em vez de static_rnn()?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9cfad",
   "metadata": {},
   "source": [
    "A. **Eficiência de Memória**:\n",
    "    - `dynamic_rnn()` utiliza um loop dinâmico (`tf.while_loop`) para processar as sequências, o que resulta em um grafo computacional menor e mais eficiente em termos de memória.\n",
    "    - Em contraste, `static_rnn()` desenrola a RNN completamente no tempo, criando uma cópia da célula para cada timestep, o que pode levar a problemas de falta de memória (OOM) para sequências longas.\n",
    "\n",
    "B. **Flexibilidade com Comprimentos de Sequência Variáveis**:\n",
    "    - `dynamic_rnn()` suporta diretamente sequências de comprimentos variáveis usando o parâmetro `sequence_length`. Isso permite que a RNN ignore os timesteps além do comprimento real da sequência, preenchendo-os com zeros automaticamente.\n",
    "    - `static_rnn()` requer que todas as sequências tenham o mesmo comprimento, o que pode ser menos prático para dados reais.\n",
    "\n",
    "C. **Desempenho Computacional**:\n",
    "    - `dynamic_rnn()` é mais rápido, pois evita a criação de um grafo muito grande e utiliza operações otimizadas para loops dinâmicos.\n",
    "    - `static_rnn()` pode ser mais lento devido ao tamanho do grafo e à sobrecarga de computação.\n",
    "\n",
    "D. **Compatibilidade com TensorFlow Moderno**:\n",
    "    - `dynamic_rnn()` é mais alinhado com as práticas modernas do TensorFlow, enquanto `static_rnn()` é considerado mais antigo e menos utilizado em implementações recentes.\n",
    "\n",
    "E. **Facilidade de Debugging e Visualização**:\n",
    "    - O grafo gerado por `dynamic_rnn()` é mais compacto e legível no TensorBoard, facilitando o debugging e a análise do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a81ee8",
   "metadata": {},
   "source": [
    "5. Como você pode lidar com sequencias de entrada de comprimento variavel? e quanto às sequencias de saída de tamanho variável?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83879e",
   "metadata": {},
   "source": [
    "- **Padding:** Preencha todas as sequências para o mesmo comprimento máximo do batch, adicionando um valor especial (geralmente zero) ao final das sequências mais curtas. Assim, todas as entradas têm o mesmo tamanho, facilitando o processamento em lote.\n",
    "- **Máscara (Masking):** Utilize máscaras para informar à RNN quais timesteps são válidos e quais são apenas padding. Em Keras, pode-se usar a camada `Masking` ou passar o argumento `mask_zero=True` em camadas de embedding.\n",
    "- **Parâmetro `sequence_length`:** Em APIs como `tf.nn.dynamic_rnn`, forneça um vetor com o comprimento real de cada sequência. A RNN ignora automaticamente os timesteps de padding durante o processamento e o cálculo do gradiente.\n",
    "\n",
    "Para **sequências de saída de comprimento variável**:\n",
    "\n",
    "- **Token de Fim de Sequência (EOS):** Adicione um token especial (por exemplo, `<eos>`) ao final de cada sequência de saída. Durante o treinamento, a função de custo só considera as saídas até o token `<eos>`, ignorando o restante.\n",
    "- **Padding e Máscara na Saída:** Assim como na entrada, preencha as saídas para o mesmo comprimento e use máscaras para garantir que a função de custo só avalie os timesteps válidos.\n",
    "- **Bucketing:** Agrupe sequências de tamanhos semelhantes em batches (buckets), reduzindo a quantidade de padding necessária e tornando o treinamento mais eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcda49",
   "metadata": {},
   "source": [
    "6. Qual é uma forma comum de se distribuir treinamento e execuçao de uma RNN profunda em várias GPUs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2fc53",
   "metadata": {},
   "source": [
    "Uma forma comum de distribuir o treinamento e a execução de uma RNN profunda em várias GPUs é dividir as camadas da RNN entre as GPUs disponíveis. Cada GPU processa uma parte do modelo, reduzindo a carga de memória e acelerando o treinamento. Aqui estão os passos principais:\n",
    "\n",
    "A. **Divisão por Camadas**:\n",
    "    - As camadas da RNN são distribuídas entre as GPUs. Por exemplo, se você tiver 4 GPUs e uma RNN com 4 camadas, cada GPU pode processar uma camada.\n",
    "\n",
    "B. **Uso de `tf.distribute.MirroredStrategy`**:\n",
    "    - O TensorFlow oferece a estratégia `tf.distribute.MirroredStrategy` para treinar modelos em várias GPUs. Ele replica o modelo em todas as GPUs e sincroniza os gradientes durante o treinamento.\n",
    "\n",
    "C. **Definição de Dispositivos**:\n",
    "    - Você pode usar `tf.device()` para especificar manualmente em qual GPU cada camada será executada. Por exemplo:\n",
    "      ```python\n",
    "      with tf.device('/gpu:0'):\n",
    "            layer1 = tf.keras.layers.SimpleRNN(...)\n",
    "      with tf.device('/gpu:1'):\n",
    "            layer2 = tf.keras.layers.SimpleRNN(...)\n",
    "      ```\n",
    "\n",
    "D. **Divisão de Dados**:\n",
    "    - Os dados de entrada são divididos em lotes menores, e cada GPU processa um lote. Isso pode ser feito automaticamente pelo TensorFlow ao usar `MirroredStrategy`.\n",
    "\n",
    "E. **Sincronização de Gradientes**:\n",
    "    - Após o cálculo dos gradientes em cada GPU, eles são sincronizados e combinados para atualizar os pesos do modelo.\n",
    "\n",
    "**Exemplo com `MirroredStrategy`:**\n",
    "```python\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "     model = tf.keras.Sequential([\n",
    "          tf.keras.layers.SimpleRNN(100, return_sequences=True, input_shape=(n_steps, n_inputs)),\n",
    "          tf.keras.layers.SimpleRNN(100),\n",
    "          tf.keras.layers.Dense(1)\n",
    "     ])\n",
    "     model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45feeb",
   "metadata": {},
   "source": [
    "7. Embedded Reber grammars foram utilizadas por Hochreiter e Schmidhuber em seu artigo sobre LSTMs. São Gramáticas artificiais que produzem strings como \"BPBTSXXVPSEPE\". Confira a bela introdução de Jenny Orr sobre este tópico. Escolha uma gramática embutida específica (como a representada na página de Jenny Orr) depois treine uma RNN para identificar se uma string respeita ou não essa gramática. Você primeiro precisará escrever uma função capaz de gerar um lote de treinamento contendo cerca de 50% de strings que respeitem a gramática e 50% que não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be34d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 7\n",
      "Shape dos dados de treinamento: (10000, 20)\n",
      "Exemplo de string válida: BTXE\n",
      "Exemplo de string inválida: BVVVPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4988 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 2/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4988 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 2/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4950 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4950 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4953 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4953 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5017 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5017 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4934 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 6/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4934 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 6/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4910 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 7/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4910 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 7/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4964 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 8/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4964 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 8/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 9/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 9/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 10/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 10/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4942 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 11/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4942 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 11/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4976 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 12/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4976 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 12/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4946 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 13/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4946 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 13/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4908 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 14/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4908 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 14/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5032 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 15/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5032 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 15/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 16/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 16/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4940 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 17/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4940 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 17/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4874 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 18/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4874 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 18/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 19/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 19/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4954 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 20/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4954 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 20/20\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4906 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4906 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "\n",
      "Acurácia no teste: 0.5000\n",
      "\n",
      "Acurácia no teste: 0.5000\n",
      "\n",
      "Resultados dos testes:\n",
      "✗ 'BTXSE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✗ 'BVPSE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✗ 'BTTXSE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✓ 'BTTTSE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "✗ 'BVPPE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✓ 'BXE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "✓ 'BTPE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "✗ 'BVPE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✓ 'BVTPE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "\n",
      "Resultados dos testes:\n",
      "✗ 'BTXSE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✗ 'BVPSE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✗ 'BTTXSE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✓ 'BTTTSE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "✗ 'BVPPE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✓ 'BXE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "✓ 'BTPE' -> Pred: 0.500 (Válido: False, Real: False)\n",
      "✗ 'BVPE' -> Pred: 0.500 (Válido: False, Real: True)\n",
      "✓ 'BVTPE' -> Pred: 0.500 (Válido: False, Real: False)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "\n",
    "# Definição da gramática Embedded Reber\n",
    "class EmbeddedReberGrammar:\n",
    "    def __init__(self):\n",
    "        self.vocab = {'B', 'T', 'V', 'X', 'P', 'S', 'E'}\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(sorted(self.vocab))}\n",
    "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def generate_valid_string(self):\n",
    "        \"\"\"Gera uma string válida segundo a gramática Embedded Reber\"\"\"\n",
    "        def generate_inner():\n",
    "            # Primeiro caractere deve ser 'B'\n",
    "            string = ['B']\n",
    "            \n",
    "            # Escolher entre caminho T ou V\n",
    "            if random.random() < 0.5:\n",
    "                string.append('T')\n",
    "                # Desenvolver caminho T\n",
    "                while random.random() < 0.7:  # Probabilidade de continuar\n",
    "                    if random.random() < 0.5:\n",
    "                        string.append('T')\n",
    "                    else:\n",
    "                        string.append('X')\n",
    "                        if random.random() < 0.5:\n",
    "                            string.append('S')\n",
    "                        break\n",
    "                else:\n",
    "                    string.append('X')\n",
    "            else:\n",
    "                string.append('V')\n",
    "                # Desenvolver caminho V\n",
    "                while random.random() < 0.7:  # Probabilidade de continuar\n",
    "                    if random.random() < 0.5:\n",
    "                        string.append('V')\n",
    "                    else:\n",
    "                        string.append('P')\n",
    "                        if random.random() < 0.5:\n",
    "                            string.append('S')\n",
    "                        break\n",
    "                else:\n",
    "                    string.append('P')\n",
    "            \n",
    "            # Finalizar com 'E'\n",
    "            string.append('E')\n",
    "            return ''.join(string)\n",
    "        \n",
    "        return generate_inner()\n",
    "    \n",
    "    def generate_invalid_string(self):\n",
    "        \"\"\"Gera uma string inválida introduzindo erros\"\"\"\n",
    "        valid_string = self.generate_valid_string()\n",
    "        string_list = list(valid_string)\n",
    "        \n",
    "        # Introduzir diferentes tipos de erros\n",
    "        error_type = random.choice(['insert', 'delete', 'replace', 'swap'])\n",
    "        \n",
    "        if len(string_list) > 3:  # Garantir que há caracteres para modificar\n",
    "            if error_type == 'insert' and len(string_list) < 15:\n",
    "                # Inserir caractere aleatório\n",
    "                pos = random.randint(1, len(string_list)-1)\n",
    "                string_list.insert(pos, random.choice(list(self.vocab - {'B', 'E'})))\n",
    "                \n",
    "            elif error_type == 'delete' and len(string_list) > 4:\n",
    "                # Deletar caractere (exceto B e E)\n",
    "                pos = random.randint(1, len(string_list)-2)\n",
    "                del string_list[pos]\n",
    "                \n",
    "            elif error_type == 'replace':\n",
    "                # Substituir caractere\n",
    "                pos = random.randint(1, len(string_list)-2)\n",
    "                string_list[pos] = random.choice(list(self.vocab - {string_list[pos], 'B', 'E'}))\n",
    "                \n",
    "            elif error_type == 'swap' and len(string_list) > 4:\n",
    "                # Trocar caracteres adjacentes\n",
    "                pos = random.randint(1, len(string_list)-3)\n",
    "                string_list[pos], string_list[pos+1] = string_list[pos+1], string_list[pos]\n",
    "        \n",
    "        return ''.join(string_list)\n",
    "    \n",
    "    def is_valid_string(self, string):\n",
    "        \"\"\"Verifica se uma string é válida segundo a gramática\"\"\"\n",
    "        if not string.startswith('B') or not string.endswith('E'):\n",
    "            return False\n",
    "        \n",
    "        # Remover B inicial e E final para análise\n",
    "        core_string = string[1:-1]\n",
    "        \n",
    "        if not core_string:\n",
    "            return False\n",
    "        \n",
    "        # Verificar padrões válidos\n",
    "        valid_patterns = [\n",
    "            'T' + 'X' * n + 'S' * m for n in range(1, 10) for m in range(2)\n",
    "        ] + [\n",
    "            'V' + 'P' * n + 'S' * m for n in range(1, 10) for m in range(2)\n",
    "        ] + [\n",
    "            'T' * n + 'X' + 'S' * m for n in range(1, 3) for m in range(2)\n",
    "        ] + [\n",
    "            'V' * n + 'P' + 'S' * m for n in range(1, 3) for m in range(2)\n",
    "        ]\n",
    "        \n",
    "        return any(pattern in core_string for pattern in valid_patterns)\n",
    "    \n",
    "    def prepare_training_data(self, num_samples=10000, max_length=20):\n",
    "        \"\"\"Prepara dados de treinamento\"\"\"\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for _ in range(num_samples // 2):\n",
    "            # Gerar string válida\n",
    "            valid_str = self.generate_valid_string()\n",
    "            X.append(valid_str)\n",
    "            y.append(1)\n",
    "            \n",
    "            # Gerar string inválida\n",
    "            invalid_str = self.generate_invalid_string()\n",
    "            X.append(invalid_str)\n",
    "            y.append(0)\n",
    "        \n",
    "        # Converter para sequences\n",
    "        X_encoded = []\n",
    "        for string in X:\n",
    "            encoded = [self.char_to_idx[char] for char in string if char in self.char_to_idx]\n",
    "            # Padding para tamanho máximo\n",
    "            if len(encoded) < max_length:\n",
    "                encoded += [0] * (max_length - len(encoded))\n",
    "            else:\n",
    "                encoded = encoded[:max_length]\n",
    "            X_encoded.append(encoded)\n",
    "        \n",
    "        return np.array(X_encoded), np.array(y)\n",
    "\n",
    "# Criar e preparar dados\n",
    "grammar = EmbeddedReberGrammar()\n",
    "X_train, y_train = grammar.prepare_training_data(10000)\n",
    "X_test, y_test = grammar.prepare_training_data(2000)\n",
    "\n",
    "print(f\"Tamanho do vocabulário: {grammar.vocab_size}\")\n",
    "print(f\"Shape dos dados de treinamento: {X_train.shape}\")\n",
    "print(f\"Exemplo de string válida: {grammar.generate_valid_string()}\")\n",
    "print(f\"Exemplo de string inválida: {grammar.generate_invalid_string()}\")\n",
    "\n",
    "# Construir modelo RNN\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=grammar.vocab_size + 1, output_dim=16, input_length=20),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Avaliar o modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nAcurácia no teste: {test_acc:.4f}\")\n",
    "\n",
    "# Função para testar strings personalizadas\n",
    "def test_custom_strings(model, grammar, test_strings):\n",
    "    \"\"\"Testa strings personalizadas no modelo treinado\"\"\"\n",
    "    results = []\n",
    "    for string in test_strings:\n",
    "        # Codificar string\n",
    "        encoded = [grammar.char_to_idx.get(char, 0) for char in string]\n",
    "        if len(encoded) < 20:\n",
    "            encoded += [0] * (20 - len(encoded))\n",
    "        else:\n",
    "            encoded = encoded[:20]\n",
    "        \n",
    "        # Fazer predição\n",
    "        prediction = model.predict(np.array([encoded]), verbose=0)[0][0]\n",
    "        is_valid = prediction > 0.5\n",
    "        actual_valid = grammar.is_valid_string(string)\n",
    "        \n",
    "        results.append({\n",
    "            'string': string,\n",
    "            'prediction': float(prediction),\n",
    "            'predicted_valid': is_valid,\n",
    "            'actual_valid': actual_valid,\n",
    "            'correct': is_valid == actual_valid\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Testar com exemplos\n",
    "test_strings = [\n",
    "    \"BTXSE\",      # Válido\n",
    "    \"BVPSE\",      # Válido  \n",
    "    \"BTTXSE\",     # Válido\n",
    "    \"BTTTSE\",     # Inválido\n",
    "    \"BVPPE\",      # Inválido\n",
    "    \"BXE\",        # Inválido\n",
    "    \"BTPE\",       # Inválido\n",
    "    grammar.generate_valid_string(),\n",
    "    grammar.generate_invalid_string()\n",
    "]\n",
    "\n",
    "results = test_custom_strings(model, grammar, test_strings)\n",
    "\n",
    "print(\"\\nResultados dos testes:\")\n",
    "for result in results:\n",
    "    status = \"✓\" if result['correct'] else \"✗\"\n",
    "    print(f\"{status} '{result['string']}' -> Pred: {result['prediction']:.3f} \"\n",
    "          f\"(Válido: {result['predicted_valid']}, Real: {result['actual_valid']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d3df2",
   "metadata": {},
   "source": [
    "8. Encare a competição Kaggle \"How much did it rain? II\" (https://goo.gl/0DS5Xe). Esta é uma tarefa de previsão de séries temporais: São fornecidas fotografias de valores de radares polarimétricos e é solicitada a previsão do total de precipitação pluviométrica por hora. A entrevista de Luis André Dutra e Silva (htpps://goolgl/fTA90W) dá algumas informações interessantes sobre as técnicas que ele utilizou para alcançar o segundo lugar na competição. Em particular ele utilizou uma RNN composta de duas camadas LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022f76e",
   "metadata": {},
   "source": [
    "9. Acesse o tutorial word2Vec (http://goo.gl/edArdi) do Tensorflow para criar uma word embedding e, em seguida, leia o tutorial Seq2Seq (https://goo.gl/L82gvs) para treinar um sistema de tradução do ingles para o francês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4781867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
