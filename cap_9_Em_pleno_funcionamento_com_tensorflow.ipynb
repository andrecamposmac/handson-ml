{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3741c3d",
   "metadata": {},
   "source": [
    "**Capítulo 9: Em pleno funcionamento com o TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada5075",
   "metadata": {},
   "source": [
    "O Capítulo 9, intitulado \"**Up and Running with TensorFlow**\" (Em Funcionamento com TensorFlow), serve como uma **introdução essencial à biblioteca TensorFlow**. Esta biblioteca é um **poderoso software de código aberto para computação numérica**, otimizado para **Machine Learning em larga escala**. O principal objetivo deste capítulo é estabelecer os fundamentos e conceitos cruciais do TensorFlow, preparando o leitor para construir redes neurais mais complexas nos capítulos subsequentes.\n",
    "\n",
    "## 1. A Filosofia do TensorFlow: Grafos de Computação\n",
    "\n",
    "O TensorFlow opera definindo um **grafo de computação em Python**. Este grafo descreve as operações e o fluxo de dados, mas **não executa nenhum cálculo no momento de sua definição**. Um programa TensorFlow é dividido em duas fases distintas:\n",
    "\n",
    "*   **Fase de Construção (Construction Phase)**: Nesta etapa, o grafo de computação é construído, representando o modelo de Machine Learning e as operações necessárias para treiná-lo.\n",
    "*   **Fase de Execução (Execution Phase)**: Nesta fase, o grafo é de fato executado, geralmente em um laço que avalia repetidamente os passos de treinamento, ajustando gradualmente os parâmetros do modelo.\n",
    "\n",
    "## 2. Executando o Grafo com Sessões\n",
    "\n",
    "Para avaliar um grafo do TensorFlow, é necessário **abrir uma sessão de TensorFlow**. A sessão é responsável por:\n",
    "\n",
    "*   **Alocar operações em dispositivos** como CPUs e GPUs.\n",
    "*   **Executar as operações** definidas no grafo.\n",
    "*   **Manter os valores de todas as variáveis**.\n",
    "\n",
    "O capítulo apresenta como usar `tf.Session()` e `tf.InteractiveSession()` para inicializar variáveis e avaliar nós no grafo. Para evitar nós duplicados em ambientes interativos, é recomendado usar `tf.reset_default_graph()`.\n",
    "\n",
    "## 3. Ciclo de Vida de um Valor de Nó\n",
    "\n",
    "Quando um nó é avaliado, o TensorFlow **determina e executa automaticamente todos os nós dos quais ele depende**. Isso garante que as operações sejam executadas na ordem correta de dependência. Os inputs e outputs são **tensores**, que são arrays multidimensionais.\n",
    "\n",
    "## 4. Implementação de Gradiente Descendente\n",
    "\n",
    "O capítulo detalha a implementação do algoritmo de **Gradiente Descendente**, uma técnica de otimização para minimizar uma função de custo.\n",
    "\n",
    "*   **Normalização**: É crucial **normalizar os vetores de características de entrada** para acelerar o treinamento.\n",
    "*   **Gradientes Manuais**: Inicialmente, discute a **computação manual dos gradientes**, um processo tedioso e propenso a erros em redes neurais profundas.\n",
    "*   **Diferenciação Automática (Autodiff)**: O TensorFlow oferece o recurso de **diferenciação automática** para calcular os gradientes de forma eficiente. O TensorFlow utiliza o **autodiff no modo reverso**, que é altamente eficiente e preciso quando há muitas entradas e poucas saídas, comum em redes neurais. A função `tf.gradients()` é usada para isso.\n",
    "*   **Otimizadores Pré-prontos**: O TensorFlow fornece otimizadores \"out-of-the-box\", como `tf.train.GradientDescentOptimizer`, que simplificam ainda mais o processo de treinamento.\n",
    "\n",
    "## 5. Visualização com TensorBoard\n",
    "\n",
    "O **TensorBoard** é uma ferramenta essencial para **visualizar e depurar grafos de computação** e monitorar o treinamento do modelo.\n",
    "\n",
    "*   **Resumos (Summaries)**: É mostrado como adicionar resumos, como `tf.summary.scalar` para monitorar o Erro Quadrático Médio (MSE).\n",
    "*   **Gravador de Arquivos (FileWriter)**: `tf.summary.FileWriter` é usado para gravar esses resumos e a definição do grafo em arquivos de log compatíveis com o TensorBoard.\n",
    "*   **Funcionalidades**: O TensorBoard permite visualizar as curvas de treinamento, a estrutura do grafo de computação e é útil para identificar erros e gargalos.\n",
    "\n",
    "## 6. Modularidade e Escopos de Nomes (Name Scopes)\n",
    "\n",
    "Para evitar código repetitivo e melhorar a legibilidade do grafo, o capítulo introduz a modularidade.\n",
    "\n",
    "*   **Funções Auxiliares**: A criação de funções para construir partes do grafo (como uma função `relu()`) ajuda a manter o código mais limpo.\n",
    "*   **Escopos de Nomes (`tf.name_scope`)**: Permitem agrupar nós relacionados no grafo. Isso torna o grafo mais claro no TensorBoard, que **colapsa séries de nós** com nomes similares para reduzir a desordem. O TensorFlow adiciona sufixos (`_1`, `_2`) para garantir nomes únicos dentro desses escopos.\n",
    "\n",
    "## 7. Compartilhamento de Variáveis\n",
    "\n",
    "O capítulo explica como **compartilhar variáveis** entre diferentes partes de um grafo complexo.\n",
    "\n",
    "*   **`tf.get_variable()` e `tf.variable_scope()`**: Em vez de passar variáveis como parâmetros, o TensorFlow oferece uma maneira mais organizada usando `tf.get_variable()` em conjunto com `tf.variable_scope()`.\n",
    "*   **Atributo `reuse`**: A função `tf.get_variable()` cria uma variável se ela não existir ou a reutiliza se já existir. O comportamento (criar ou reutilizar) é controlado pelo atributo `reuse` do `tf.variable_scope()` atual. Variáveis criadas com `get_variable()` são nomeadas com o prefixo do `variable_scope`, que também funciona como um `name_scope` para outros nós.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9018e",
   "metadata": {},
   "source": [
    "### **Implementação:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a22b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b780e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_13144\\1448479550.py:1: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\tx = tf.compat.v1.Variable(3, name='x')\n",
    "\ty = tf.compat.v1.Variable(4, name='y')\n",
    "\tf = x**x * y + y + 2\n",
    "\n",
    "\tsess = tf.compat.v1.Session()\n",
    "\tsess.run(tf.compat.v1.global_variables_initializer())\n",
    "\tresult = sess.run(f)\n",
    "\tprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e911679",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e097a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.InteractiveSession(graph=graph)\n",
    "sess.run(init)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fde2fc",
   "metadata": {},
   "source": [
    "**Gerenciando Grafos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432b0da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.compat.v1.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09388d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ab1a0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c764a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.compat.v1.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f0bf80",
   "metadata": {},
   "source": [
    "**Ciclo de vida do nó**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271629ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "w = tf.compat.v1.Variable(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    print(sess.run(y))\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80bc577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5d99c",
   "metadata": {},
   "source": [
    "Regressão linear com Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37dd48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.linalg.inv(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "467facb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    theta_value = sess.run(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8186a226",
   "metadata": {},
   "source": [
    "Implementando o Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90fbc0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 12.782243\n",
      "Epoch 100 MSE = 4.9373193\n",
      "Epoch 200 MSE = 4.8748503\n",
      "Epoch 300 MSE = 4.855022\n",
      "Epoch 400 MSE = 4.841163\n",
      "Epoch 500 MSE = 4.8310885\n",
      "Epoch 600 MSE = 4.823741\n",
      "Epoch 700 MSE = 4.8183727\n",
      "Epoch 800 MSE = 4.814443\n",
      "Epoch 900 MSE = 4.811562\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.compat.v1.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6dc02",
   "metadata": {},
   "source": [
    "Utilizando um otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59f22d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0c23d",
   "metadata": {},
   "source": [
    "Fornecendo Dados ao Algoritmo de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53753ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.  9. 10. 11. 12. 13. 14.]]\n",
      "[[ 9. 10. 11. 12. 13. 14.  6.  7.  8.]\n",
      " [12. 13. 14.  6.  7.  8.  9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.compat.v1.placeholder(tf.float32, shape=(None, n + 1), name='A')\n",
    "B = A + 5\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3, 4, 5, 6, 7, 8, 9]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6, 7, 8, 9, 1, 2, 3], [7, 8, 9, 1, 2, 3, 4, 5, 6]]})\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc11a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.compat.v1.placeholder(tf.float32, shape=(None, 1), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a89bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b140507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f757a96",
   "metadata": {},
   "source": [
    "Salvando e restaurando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "467b2f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 0, batch 0\n",
      "Model saved at epoch 100, batch 0\n",
      "Model saved at epoch 200, batch 0\n",
      "Model saved at epoch 300, batch 0\n",
      "Model saved at epoch 400, batch 0\n",
      "Model saved at epoch 500, batch 0\n",
      "Model saved at epoch 600, batch 0\n",
      "Model saved at epoch 700, batch 0\n",
      "Model saved at epoch 800, batch 0\n",
      "Model saved at epoch 900, batch 0\n",
      "Final model saved.\n"
     ]
    }
   ],
   "source": [
    "theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            if epoch % 100 == 0 and batch_index == 0:\n",
    "                save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "                print(f\"Model saved at epoch {epoch}, batch {batch_index}\")\n",
    "\n",
    "    best_theta = sess.run(theta)\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    print(\"Final model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebd220aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cdfa5",
   "metadata": {},
   "source": [
    "salvando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5197e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.compat.v1.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f18ac",
   "metadata": {},
   "source": [
    "restaurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ad6f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.compat.v1.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f5482",
   "metadata": {},
   "source": [
    "Vasualização de Grafo e curvas de treinamento com Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2a252c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_13144\\3091642509.py:1: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
     ]
    }
   ],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8fdac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_13144\\2780189875.py:2: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_summary = tf.compat.v1.summary.scalar('MSE', mse)\n",
    "file_writer = tf.compat.v1.summary.FileWriter(logdir, tf.compat.v1.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24b2eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for batch_index in range(n_batches):\n",
    "        X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "        if epoch % 10 == 0:\n",
    "            summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch}, session=sess)\n",
    "            file_writer.add_summary(summary_str, epoch * n_batches + batch_index)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5542e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22faae",
   "metadata": {},
   "source": [
    "Escopos do Nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d18cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error, name=\"mse\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2951db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1e27fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1/Mean\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29029c41",
   "metadata": {},
   "source": [
    "Modulariadade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b06985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random.truncated_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.matmul(X, w) + b\n",
    "    return tf.maximum(z, 0.0, name = \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d678da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.compat.v1.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb802e5",
   "metadata": {},
   "source": [
    "Compartilhando variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f67cf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(x.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random.truncated_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.matmul(x, w) + b\n",
    "        return tf.maximum(z, 0.0, name = \"max\")\n",
    "\n",
    "threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "X = tf.compat.v1.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1ec7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.variable_scope(\"\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\tthreshold = tf.compat.v1.get_variable(\"threshold\", shape=(), initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b37b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.compat.v1.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.compat.v1.get_variable(\"threshold\", shape=(), initializer=tf.compat.v1.zeros_initializer())\n",
    "        return tf.maximum(X - threshold, 0.0)\n",
    "    \n",
    "X = tf.compat.v1.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "with tf.compat.v1.variable_scope(\"relu\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "    threshold = tf.compat.v1.get_variable(\"threshold\", shape=(), initializer=tf.compat.v1.zeros_initializer())\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba90e4e",
   "metadata": {},
   "source": [
    "### **Exercícios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979ca0b",
   "metadata": {},
   "source": [
    "1. Quais são os principais benefícios de se criar um grafo de cálculo em vez de executar diretamente os cálculos? Quais são as principais desvantagens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955306b",
   "metadata": {},
   "source": [
    "**Benefícios:**\n",
    "- **Eficiência:** O grafo de cálculo permite otimizações automáticas, como paralelismo e execução em dispositivos especializados (GPUs/TPUs).\n",
    "- **Portabilidade:** Um grafo pode ser salvo e carregado em diferentes ambientes, facilitando a reutilização e o compartilhamento.\n",
    "- **Visualização:** Ferramentas como o TensorBoard permitem inspecionar e depurar o grafo, ajudando a entender o fluxo de dados e operações.\n",
    "- **Modularidade:** O grafo organiza as operações de forma clara, permitindo reutilização de subcomponentes e melhor manutenção do código.\n",
    "- **Execução Diferida:** A separação entre construção e execução permite definir todo o modelo antes de executá-lo, o que é útil para depuração e planejamento.\n",
    "\n",
    "**Desvantagens:**\n",
    "- **Complexidade:** A criação de grafos pode ser mais difícil de entender e implementar, especialmente para iniciantes.\n",
    "- **Menor Flexibilidade:** A execução diferida pode dificultar a depuração, já que os valores intermediários não estão disponíveis até a execução.\n",
    "- **Sobrecarga Inicial:** A construção do grafo pode adicionar uma sobrecarga inicial, especialmente para tarefas simples.\n",
    "- **Curva de Aprendizado:** Requer familiaridade com conceitos como tensores, sessões e escopos, o que pode ser desafiador para novos usuários.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0adc3",
   "metadata": {},
   "source": [
    "2. A declaração \"a_val = a.eval(session=sess)\" é equivalente a \"a_val = sess.run(a)\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5b59c",
   "metadata": {},
   "source": [
    "Sim, a declaração `a_val = a.eval(session=sess)` é equivalente a `a_val = sess.run(a)` no TensorFlow 1.x. Ambas executam o nó `a` no grafo de computação dentro da sessão `sess` e retornam o valor resultante. A diferença é apenas sintática:\n",
    "- `a.eval(session=sess)` é um método do próprio tensor, onde você especifica a sessão.\n",
    "- `sess.run(a)` é um método da sessão, onde você especifica o tensor a ser avaliado.\n",
    "Ambas as formas são válidas e produzem o mesmo resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280c31e",
   "metadata": {},
   "source": [
    "3. A declaração a_val, b_val = a.val(session=sess), b.eval(session=sess) é equivalente a a_val, b_val = sess.run([a,b])?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacab5af",
   "metadata": {},
   "source": [
    "Sim, a declaração `a_val, b_val = a.eval(session=sess), b.eval(session=sess)` é funcionalmente equivalente a `a_val, b_val = sess.run([a, b])` no TensorFlow 1.x. Ambas avaliam os tensores `a` e `b` na mesma sessão e retornam seus valores.\n",
    "No entanto, usar `sess.run([a, b])` é mais eficiente, pois ambos os tensores são avaliados em uma única execução do grafo, aproveitando o compartilhamento de operações intermediárias. Avaliar separadamente pode resultar em cálculos duplicados se `a` e `b` compartilharem partes do grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203700b",
   "metadata": {},
   "source": [
    "4. É possível executar dois grafos na mesma sessão?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e312e",
   "metadata": {},
   "source": [
    "Não, no TensorFlow 1.x, uma sessão (`tf.Session`) está associada a um único grafo de computação. Se você tentar executar operações de dois grafos diferentes na mesma sessão, ocorrerá um erro. No entanto, você pode criar múltiplas sessões, cada uma associada a um grafo diferente, ou usar o método `with graph.as_default()` para alternar entre grafos no mesmo código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba3ee8",
   "metadata": {},
   "source": [
    "5. Se você criar um grafo g contendo uma variável w, então iniciar dois segmentos e abrir uma sessão em cada, ambos utilizando o mesmo grafo g, cada sessão terá sua própria cópia da variável w ou esta será compartilhada?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6f4e9",
   "metadata": {},
   "source": [
    "Cada sessão terá sua própria cópia da variável `w`. No TensorFlow 1.x, as variáveis são armazenadas no contexto da sessão, e cada sessão mantém seu próprio estado das variáveis. Isso significa que, mesmo que as sessões compartilhem o mesmo grafo, as variáveis não são compartilhadas entre elas. Cada sessão inicializa e gerencia suas próprias instâncias das variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16adb4",
   "metadata": {},
   "source": [
    "6. Quando uma variável é iniciada? Quando é destruída?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1540681",
   "metadata": {},
   "source": [
    "**Início:**\n",
    "Uma variável no TensorFlow 1.x é iniciada explicitamente ao executar a operação de inicialização, como `sess.run(tf.global_variables_initializer())`, ou ao executar uma operação que depende dela. Até que seja inicializada, a variável não possui valor.\n",
    "\n",
    "**Destruição:**\n",
    "Uma variável é destruída quando a sessão associada a ela é fechada. Como as variáveis são armazenadas no contexto da sessão, fechar a sessão (`sess.close()`) libera os recursos alocados para essas variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ed257",
   "metadata": {},
   "source": [
    "7. Qual é a diferença entre um placeholder e uma variável?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d2f58",
   "metadata": {},
   "source": [
    "**Placeholder:**\n",
    "- Um placeholder é um nó no grafo que serve como entrada para os dados. Ele não armazena nenhum valor por si só.\n",
    "- É usado para alimentar dados no grafo durante a execução, utilizando o argumento `feed_dict` em uma sessão.\n",
    "- Deve ter seu valor fornecido no momento da execução, caso contrário, ocorrerá um erro.\n",
    "- Exemplo: `X = tf.compat.v1.placeholder(tf.float32, shape=(None, n_features), name='X')`\n",
    "\n",
    "**Variável:**\n",
    "- Uma variável é um nó no grafo que armazena um valor persistente, que pode ser atualizado durante a execução.\n",
    "- É usada para armazenar pesos, vieses ou outros parâmetros do modelo.\n",
    "- Deve ser inicializada explicitamente antes de ser usada.\n",
    "- Exemplo: `theta = tf.Variable(tf.random.uniform([n + 1, 1], -1.0, 1.0), name='theta')`\n",
    "\n",
    "**Resumo:**\n",
    "- Placeholders são usados para fornecer dados ao grafo, enquanto variáveis são usadas para armazenar e atualizar valores durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f687e3d",
   "metadata": {},
   "source": [
    "8. O que acontece quando você executa o grafo para avaliar uma operação que depende de um placeholder, mas você não fornece seu valor? O que acontece se a operação não depender do placeholder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f52d17",
   "metadata": {},
   "source": [
    "- **Se a operação depender do placeholder:** O TensorFlow lançará um erro (`InvalidArgumentError`) porque o valor do placeholder não foi fornecido. Placeholders exigem que seus valores sejam passados por meio do argumento `feed_dict` durante a execução.\n",
    "\n",
    "- **Se a operação não depender do placeholder:** A operação será avaliada normalmente, pois o placeholder não é necessário para calcular o resultado. Nesse caso, o TensorFlow ignora o placeholder durante a execução."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e41f4",
   "metadata": {},
   "source": [
    "9. Quando você executa um grafo, você pode fornecer o valor de saída de qualquer operação ou apenas o valor dos placeholders?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbfe8b",
   "metadata": {},
   "source": [
    "Quando você executa um grafo no TensorFlow 1.x, você pode fornecer valores apenas para os placeholders. Esses valores são passados por meio do argumento `feed_dict` na chamada de execução da sessão (`sess.run()`).\n",
    "\n",
    "As operações no grafo, por outro lado, não podem ter seus valores fornecidos diretamente. Elas são calculadas automaticamente com base nos valores dos placeholders e nas dependências definidas no grafo. O TensorFlow avalia as operações necessárias para produzir o resultado solicitado, seguindo o fluxo de dependências do grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea73a1",
   "metadata": {},
   "source": [
    "10. Como você pode definir uma variável para qualquer valor desejado (durante a fase de execução)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94618028",
   "metadata": {},
   "source": [
    "Para definir uma variável para qualquer valor desejado durante a fase de execução no TensorFlow 1.x, você pode usar o método `assign()` ou o método `feed_dict` com um placeholder associado à variável. Aqui está como fazer isso:\n",
    "\n",
    "1. **Usando `assign`:**\n",
    "    ```python\n",
    "    assign_op = variable.assign(new_value)\n",
    "    sess.run(assign_op)\n",
    "    ```\n",
    "\n",
    "2. **Usando um placeholder:**\n",
    "    ```python\n",
    "    placeholder = tf.compat.v1.placeholder(dtype=tf.float32, shape=variable.shape)\n",
    "    assign_op = variable.assign(placeholder)\n",
    "    sess.run(assign_op, feed_dict={placeholder: new_value})\n",
    "    ```\n",
    "\n",
    "Ambos os métodos permitem atualizar o valor da variável durante a execução do grafo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc0232",
   "metadata": {},
   "source": [
    "11. Quantas vezes o autodiff de modo reverso precisa percorrer o gráfico para calcular os gradientes da função de custo em relação a dez variáveis? E quanto ao autodiff do modo avançado? E a diferenciação simbólica?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cf9eb",
   "metadata": {},
   "source": [
    "- **Autodiff de modo reverso:** O autodiff de modo reverso percorre o gráfico **uma única vez** para calcular os gradientes da função de custo em relação a todas as dez variáveis. Isso ocorre porque ele acumula os gradientes de forma eficiente durante a retropropagação.\n",
    "\n",
    "- **Autodiff do modo avançado:** O autodiff do modo avançado precisaria percorrer o gráfico **dez vezes**, uma vez para cada variável, porque ele calcula os gradientes de forma independente para cada variável.\n",
    "\n",
    "- **Diferenciação simbólica:** A diferenciação simbólica não percorre o gráfico, mas gera expressões analíticas para os gradientes. No entanto, essas expressões podem ser computacionalmente caras e propensas a explosão de complexidade para gráficos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37b640",
   "metadata": {},
   "source": [
    "12. Implemente a Regressão Logística com Gradiente Descendente utilizando Minilotes no TensorFlow. Treine e avalie o modelo no conjunto de dados em formato de luas. Adicione as seguintes funcionalidades:\n",
    "\n",
    "**A. Definição do Grafo**\n",
    "- Crie o grafo dentro da função `logistic_regression()`, permitindo reutilização fácil.\n",
    "\n",
    "**B. Salvamento de Pontos de Verificação**\n",
    "- Utilize um `Saver` para salvar pontos de verificação em intervalos regulares durante o treinamento.\n",
    "- Salve o modelo final ao término do treinamento.\n",
    "\n",
    "**C. Restauração de Pontos de Verificação**\n",
    "- Restaure o último ponto de verificação automaticamente após a inicialização, caso o treinamento seja interrompido.\n",
    "\n",
    "**D. Escopos de Nome**\n",
    "- Defina o grafo utilizando escopos de nome (`name_scope`) para melhorar a visualização no TensorBoard.\n",
    "\n",
    "**E. Resumos para o TensorBoard**\n",
    "- Adicione resumos (`summaries`) para visualizar as curvas de aprendizado no TensorBoard.\n",
    "\n",
    "**F. Ajuste de Hiperparâmetros**\n",
    "- Experimente ajustar hiperparâmetros, como:\n",
    "    - Taxa de aprendizado (`learning_rate`)\n",
    "    - Tamanho do minilote (`batch_size`)\n",
    "- Observe como essas alterações afetam a curva de aprendizado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
